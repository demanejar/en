<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://demanejar.github.io/en/</id><title>De Manejar</title><subtitle>(c) Copyright Demanejar. A small website about Bigdata writen by team Demanejar.</subtitle> <updated>2024-04-01T00:05:13+07:00</updated> <author> <name>demanejar</name> <uri>https://demanejar.github.io/en/</uri> </author><link rel="self" type="application/atom+xml" href="https://demanejar.github.io/en/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="https://demanejar.github.io/en/"/> <generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator> <rights> © 2024 demanejar </rights> <icon>/en/assets/img/favicons/favicon.ico</icon> <logo>/en/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Project Socket Stream with Spark Streaming</title><link href="https://demanejar.github.io/en/posts/socket-stream/" rel="alternate" type="text/html" title="Project Socket Stream with Spark Streaming" /><published>2021-09-23T20:52:00+07:00</published> <updated>2022-09-24T17:55:50+07:00</updated> <id>https://demanejar.github.io/en/posts/socket-stream/</id> <content src="https://demanejar.github.io/en/posts/socket-stream/" /> <author> <name>demanejar</name> </author> <category term="Hadoop &amp; Spark" /> <category term="Spark" /> <summary> In this post, we consider a small example with Spark Streaming. My work is creating a project with Spark Streaming listen in port 7777 and filter line contain “error” word and print it to console. Project preparation This is a simple project write by Scala. You can see all project in https://github.com/demanejar/socket-stream, please clone this project to your local before run it. There are ... </summary> </entry> <entry><title>Summary of questions about Apache Hadoop</title><link href="https://demanejar.github.io/en/posts/hadoop-question/" rel="alternate" type="text/html" title="Summary of questions about Apache Hadoop" /><published>2021-08-09T20:52:00+07:00</published> <updated>2024-02-10T11:00:44+07:00</updated> <id>https://demanejar.github.io/en/posts/hadoop-question/</id> <content src="https://demanejar.github.io/en/posts/hadoop-question/" /> <author> <name>demanejar</name> </author> <category term="Hadoop &amp; Spark" /> <category term="Hadoop" /> <summary> The main goal of Apache Hadoop Open data storage and powerful data processing. Save costs when storing and processing large amounts of data. You can see more details about Hadoop’s goals HERE Hadoop solves the problem of fault tolerance through what technique? Hadoop is fault tolerant through redundancy engineering Files are fragmented, fragments are replicated to other no... </summary> </entry> <entry><title>Hadoop MapReduce and basic WordCount program with MapReduce</title><link href="https://demanejar.github.io/en/posts/hadoop-mapreduce-and-wordcount-project/" rel="alternate" type="text/html" title="Hadoop MapReduce and basic WordCount program with MapReduce" /><published>2021-08-03T16:00:00+07:00</published> <updated>2023-12-03T14:28:47+07:00</updated> <id>https://demanejar.github.io/en/posts/hadoop-mapreduce-and-wordcount-project/</id> <content src="https://demanejar.github.io/en/posts/hadoop-mapreduce-and-wordcount-project/" /> <author> <name>demanejar</name> </author> <category term="Hadoop &amp; Spark" /> <category term="Hadoop" /> <summary> MapReduce is a processing technique and a programming model for distributed computing to deploy and process big data. Hadoop MapReduce is a data processing framework of Hadoop built on the idea of ​​MapReduce, now when we talk about MapReduce we will immediately think of Hadoop MapReduce, so in this article I would like to briefly talk about some places. Hadoop MapReduce is MapReduce. To bette... </summary> </entry> <entry><title>Commands for manipulating files and directories on HDFS</title><link href="https://demanejar.github.io/en/posts/hdfs-commands/" rel="alternate" type="text/html" title="Commands for manipulating files and directories on HDFS" /><published>2021-07-06T16:00:00+07:00</published> <updated>2022-09-12T19:15:11+07:00</updated> <id>https://demanejar.github.io/en/posts/hdfs-commands/</id> <content src="https://demanejar.github.io/en/posts/hdfs-commands/" /> <author> <name>demanejar</name> </author> <category term="Hadoop &amp; Spark" /> <category term="Hadoop" /> <summary> The commands on HDFS are generally quite similar to the commands on Linux, both in terms of their functions and names, if you are familiar with Linux/Ubuntu then you probably don’t need to learn much, so apply. just use it. help Ask about common line in HDFS : hdfs dfs -help hdfs dfs -usege &amp;lt;utility_name&amp;gt; Ask about a specific command: hdfs dfs -help &amp;lt;statement&amp;gt; VD: hdfs dfs -h... </summary> </entry> <entry><title>HDFS</title><link href="https://demanejar.github.io/en/posts/hdfs-introduction/" rel="alternate" type="text/html" title="HDFS" /><published>2021-07-04T16:00:00+07:00</published> <updated>2023-12-03T14:28:47+07:00</updated> <id>https://demanejar.github.io/en/posts/hdfs-introduction/</id> <content src="https://demanejar.github.io/en/posts/hdfs-introduction/" /> <author> <name>demanejar</name> </author> <category term="Hadoop &amp; Spark" /> <category term="Hadoop" /> <summary> Hadoop Distributed File System (HDFS) is a distributed storage system designed to run on common hardware. Highly fault-tolerant HDFS is implemented using low-cost hardware. HDFS provides high-throughput access to application data so it is well suited for applications with large data sets. Objective of HDFS Save money on large data storage: can store megabytes to petabytes of data, in ... </summary> </entry> </feed>
