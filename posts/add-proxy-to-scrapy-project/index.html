<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:image" content="https://raw.githubusercontent.com/demanejar/image-collection/main/crawldataalonhadata/img_603b96633d2d0.png"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-9TR0K3B846"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8714452693053438" crossorigin="anonymous"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-9TR0K3B846'); </script><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Configuring Proxy for Scrapy Project" /><meta name="author" content="trannguyenhan" /><meta property="og:locale" content="en_US" /><meta name="description" content="Proxy is probably a concept that’s no longer unfamiliar to everyone. For people working on data crawling, proxy is like an inseparable companion. In this article, I will guide how to configure proxy for a Scrapy project. The project I use as an example for this article is the crawl alonhadat project https://github.com/demanejar/crawl-alonhadat." /><meta property="og:description" content="Proxy is probably a concept that’s no longer unfamiliar to everyone. For people working on data crawling, proxy is like an inseparable companion. In this article, I will guide how to configure proxy for a Scrapy project. The project I use as an example for this article is the crawl alonhadat project https://github.com/demanejar/crawl-alonhadat." /><link rel="canonical" href="https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/" /><meta property="og:url" content="https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/" /><meta property="og:site_name" content="De Manejar" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-02-15T20:52:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Configuring Proxy for Scrapy Project" /><meta name="twitter:site" content="@DeManejar" /><meta name="twitter:creator" content="@trannguyenhan" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"trannguyenhan"},"dateModified":"2023-02-15T20:52:00+07:00","datePublished":"2023-02-15T20:52:00+07:00","description":"Proxy is probably a concept that’s no longer unfamiliar to everyone. For people working on data crawling, proxy is like an inseparable companion. In this article, I will guide how to configure proxy for a Scrapy project. The project I use as an example for this article is the crawl alonhadat project https://github.com/demanejar/crawl-alonhadat.","headline":"Configuring Proxy for Scrapy Project","mainEntityOfPage":{"@type":"WebPage","@id":"https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/"},"url":"https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/"}</script><title>Configuring Proxy for Scrapy Project | De Manejar</title><link rel="shortcut icon" href="/en/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/en/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/en/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/en/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/en/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/en/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/en/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/en/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/en/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/en/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/en/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/en/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/en/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/en/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/en/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/en/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/en/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/en/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/en/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/en/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/en/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/en/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/en/" alt="avatar" class="mx-auto"> <img src="https://i.pinimg.com/564x/9c/32/79/9c3279b5ac960533cbcb7e833ac4d947.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/en/">De Manejar</a></div><div class="site-subtitle font-italic">Hello Bigdata !</div></div><ul class="w-100"><li class="nav-item"> <a href="/en/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/en/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/en/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/en/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/en/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/demanejar" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/DeManejar" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['demanejar','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/en/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/en/"> Posts </a> </span> <span>Configuring Proxy for Scrapy Project</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Configuring Proxy for Scrapy Project</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> trannguyenhan </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Feb 15, 2023, 8:52 PM +0700" prep="on" > Feb 15, 2023 <i class="unloaded">2023-02-15T20:52:00+07:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1448 words">8 min</span></div></div><div class="post-content"><p>Proxy is probably a concept that’s no longer unfamiliar to everyone. For people working on data crawling, proxy is like an inseparable companion. In this article, I will guide how to configure proxy for a Scrapy project. The project I use as an example for this article is the crawl alonhadat project <a href="https://github.com/demanejar/crawl-alonhadat">https://github.com/demanejar/crawl-alonhadat</a>.</p><blockquote><p>For each of my articles like this one “Configuring Proxy for Scrapy Project”, but I don’t want to only talk about how to configure proxy in the project. I want to talk a bit more broadly about related issues. If you’re interested in the main point of how to configure proxy for a Scrapy project, you can skip this introduction and scroll down a bit more to the next section of the article.</p></blockquote><h2 id="proxy-and-websites-blocking-bots-based-on-abnormal-traffic">Proxy and Websites Blocking Bots Based on Abnormal Traffic</h2><p>In the previous article, we analyzed the website and wrote a program to collect data. However, that’s not enough. Now alonhadat has implemented banning IPs that have high traffic within a certain time period. The most obvious thing is that just running the project for about 4-5 minutes (or less, just 2-3 minutes) will see a bunch of exceptions generated, and after accessing the alonhadat website again, you’ll get the result:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/crawldataalonhadata/alonhadat_ban_bot.png" alt="" /></p><p>With this image, we can temporarily predict that alonhadat is blocking bots by IP, because besides bots being forced to pass captcha, real users entering the website are also being forced to pass captcha. This method is one of the simplest ways to protect websites from crawling bots. Just see any IP with abnormal traffic and ban it immediately. After 1-2 days or 1-2 months, unban it, and if it’s abnormal again, ban it again.</p><p>For websites using this blocking method, there are basically 2 ways to avoid it:</p><ul><li><p>1 is to use proxies, lots of proxies. It depends on how the website blocks. If the blocking threshold of the website is small (threshold here I’m referring to is the number of website accesses within a certain time period), then we’ll need a lot of proxies. If this threshold is higher, we may need fewer proxies. As for how many proxies are enough, it needs to be tested. For example, before I crawled the website <a href="https://www.yelp.com/">https://www.yelp.com/</a>, I used a pool with 10 proxies, each request spaced 2 seconds apart, and each request would pick a random proxy to access the website. After 2-3 hours, all 10 proxies were banned. So I decided to increase to 100. This time it lasted longer, after one night all 100 proxies were also banned. The problem is now we need even more proxies. What about 1000? And that’s just a prediction, and because 1000 proxies cost so much money, I decided to stop.</p><li><p>2 is harder, which is to write a script to bypass captcha. This method isn’t always usable because some websites block directly instead of forcing users to pass captcha to continue viewing content. A typical example is <a href="https://www.yelp.com/">https://www.yelp.com/</a>, and this website of course has a higher blocking threshold. Since these captchas are very easy to change to another type, the scripts you write will also only work for a fairly short time. And currently there are also many very complex types of captchas. Being able to bypass these new types of captchas is generally difficult.</p></ul><p>This blocking method also brings a pretty bad experience for users. When I was crawling, alonhadat was banning my IP and I had to pass captcha when entering the website, but my roommates using the same WiFi and having the same IP were also being forced to pass captcha like that even though they didn’t do anything. So it’s possible that the website is using this method temporarily while they research to have a better solution.</p><h2 id="data-flow-and-architecture-of-scrapy">Data Flow and Architecture of Scrapy</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/scrapy_structure.png" alt="" /></p><p>Scrapy consists of 6 components:</p><ul><li><p>Scrapy Engine: responsible for controlling data flow between components in the system, triggering some events under certain conditions</p><li><p>Downloader: finds and downloads HTML code segments from specified websites</p><li><p>Spiders: this is where we mainly work, where we write code to analyze websites</p><li><p>Item Pipeline: responsible for processing Items extracted and created by Spiders</p><li><p>Middleware: there will be 2 types of middleware. 1 is middleware between Spiders and Engine. This middleware is usually used less because code written in Spider Middleware can also be replaced by writing in Spiders or Item Pipeline. 2 is Downloader Middleware between Downloader and Engine. It aims to process requests before they are sent to Downloader. The most typical example is adding proxy to requests</p></ul><p>By understanding each component and the function of each component, I’m sure everyone has imagined that we will configure proxy for each request in Downloader Middleware.</p><h2 id="configuring-proxy-for-scrapy-project">Configuring Proxy for Scrapy Project</h2><p>If you don’t know which website to use proxies from, you can refer to the website <a href="https://www.webshare.io/?referral_code=ttjajplnrle1">https://proxy.webshare.io/</a>. Proxies on this website are cheap and quite good quality. Each account also has 10 free proxies for testing.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/scrapy/proxy_webshareio.png" alt="" /></p><p>Go to <code class="language-plaintext highlighter-rouge">Proxy -&gt; List -&gt; Download</code> to download the proxy list. Rename the downloaded file to proxies.txt and copy it to the project folder.</p><p>The <code class="language-plaintext highlighter-rouge">middlewares.py</code> file is where the code for Spider Middleware and Downloader Middleware is stored. In the file, there are 2 classes and methods defined and commented clearly on how to use them.</p><p>To add proxy to requests before they are sent to Downloader, we will write in the <code class="language-plaintext highlighter-rouge">process_request</code> function of the <code class="language-plaintext highlighter-rouge">DataPriceDownloaderMiddleware</code> class:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">w3lib.http</span> <span class="kn">import</span> <span class="n">basic_auth_header</span>
<span class="kn">import</span> <span class="n">random</span>

<span class="n">proxyPools</span> <span class="o">=</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">data_price/proxies.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">).</span><span class="nf">read</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DataPriceDownloaderMiddleware</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="c1"># Not all methods need to be defined. If a method is not defined,
</span>    <span class="c1"># scrapy acts as if the downloader middleware does not modify the
</span>    <span class="c1"># passed objects.
</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="c1"># This method is used by Scrapy to create your spiders.
</span>        <span class="n">s</span> <span class="o">=</span> <span class="nf">cls</span><span class="p">()</span>
        <span class="n">crawler</span><span class="p">.</span><span class="n">signals</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span><span class="n">s</span><span class="p">.</span><span class="n">spider_opened</span><span class="p">,</span> <span class="n">signal</span><span class="o">=</span><span class="n">signals</span><span class="p">.</span><span class="n">spider_opened</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">s</span>

    <span class="k">def</span> <span class="nf">process_request</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1"># Called for each request that goes through the downloader
</span>        <span class="c1"># middleware.
</span>
        <span class="c1"># Must either:
</span>        <span class="c1"># - return None: continue processing this request
</span>        <span class="c1"># - or return a Response object
</span>        <span class="c1"># - or return a Request object
</span>        <span class="c1"># - or raise IgnoreRequest: process_exception() methods of
</span>        <span class="c1">#   installed downloader middleware will be called
</span>        <span class="k">return</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">process_response</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1"># Called with the response returned from the downloader.
</span>
        <span class="c1"># Must either;
</span>        <span class="c1"># - return a Response object
</span>        <span class="c1"># - return a Request object
</span>        <span class="c1"># - or raise IgnoreRequest
</span>
        <span class="n">proxy</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">proxyPools</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">:</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">httpsProxy</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">portProxy</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">usernameProxy</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">passwordProxy</span> <span class="o">=</span> <span class="n">proxy</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

        <span class="n">request</span><span class="p">.</span><span class="n">meta</span><span class="p">[</span><span class="sh">'</span><span class="s">proxy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">http://</span><span class="sh">"</span> <span class="o">+</span> <span class="n">httpsProxy</span> <span class="o">+</span> <span class="sh">"</span><span class="s">:</span><span class="sh">"</span> <span class="o">+</span> <span class="n">portProxy</span>
        <span class="n">request</span><span class="p">.</span><span class="n">headers</span><span class="p">[</span><span class="sh">'</span><span class="s">Proxy-Authorization</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">basic_auth_header</span><span class="p">(</span><span class="n">usernameProxy</span><span class="p">,</span> <span class="n">passwordProxy</span><span class="p">)</span> 

        <span class="k">return</span> <span class="n">response</span>

    <span class="k">def</span> <span class="nf">process_exception</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">exception</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1"># Called when a download handler or a process_request()
</span>        <span class="c1"># (from other downloader middleware) raises an exception.
</span>
        <span class="c1"># Must either:
</span>        <span class="c1"># - return None: continue processing this exception
</span>        <span class="c1"># - return a Response object: stops process_exception() chain
</span>        <span class="c1"># - return a Request object: stops process_exception() chain
</span>        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">spider_opened</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="n">spider</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">'</span><span class="s">Spider opened: %s</span><span class="sh">'</span> <span class="o">%</span> <span class="n">spider</span><span class="p">.</span><span class="n">name</span><span class="p">)</span>
</pre></table></code></div></div><ul><li><p>We define a <code class="language-plaintext highlighter-rouge">proxyPools</code> beforehand that reads from the <code class="language-plaintext highlighter-rouge">proxies.txt</code> file just added to the project</p><li><p>In <code class="language-plaintext highlighter-rouge">process_request</code>, we will pick a random proxy and add it to headers</p></ul><p>Now go to the <code class="language-plaintext highlighter-rouge">settings.py</code> file, find the <code class="language-plaintext highlighter-rouge">DOWNLOADER_MIDDLEWARES</code> location, uncomment it, and add another <code class="language-plaintext highlighter-rouge">HttpProxyMiddleware</code> so these Middlewares are called when starting to crawl:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">DOWNLOADER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware</span><span class="sh">'</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>  
    <span class="sh">'</span><span class="s">data_price.middlewares.DataPriceDownloaderMiddleware</span><span class="sh">'</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
<span class="p">}</span>
</pre></table></code></div></div><p>Set the number of <code class="language-plaintext highlighter-rouge">HttpProxyMiddleware</code> larger than <code class="language-plaintext highlighter-rouge">DataPriceDownloaderMiddleware</code> so it’s called after. The numbers <code class="language-plaintext highlighter-rouge">543</code> and <code class="language-plaintext highlighter-rouge">600</code> are priorities so the system knows which one to call first.</p><p>Now run the project again and we’ll see results returned one by one, whereas just now there were many <code class="language-plaintext highlighter-rouge">exception</code> errors due to elements not being found:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://raw.githubusercontent.com/demanejar/image-collection/main/crawldataalonhadata/proxy_alonhadat_1.png" alt="" /></p><p>You can add a proxy pool with more proxies and add delay time in <code class="language-plaintext highlighter-rouge">settings.py</code> to avoid requests being sent too quickly and continuously:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mi">2</span>
</pre></table></code></div></div><p>View detailed project at: <a href="https://github.com/demanejar/crawl-alonhadat/blob/master/data_price/middlewares.py">https://github.com/demanejar/crawl-alonhadat</a></p><h2 id="using-libraries-to-configure-proxy-for-scrapy-project">Using Libraries to Configure Proxy for Scrapy Project</h2><p>The library I’m talking about here is <a href="https://github.com/TeamHG-Memex/scrapy-rotating-proxies">Rotating proxies</a>.</p><p>Installing Rotating proxies:</p><div class="language-bash highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>pip <span class="nb">install </span>scrapy-rotating-proxies
</pre></table></code></div></div><p>Add the <code class="language-plaintext highlighter-rouge">ROTATING_PROXY_LIST</code> variable to the <code class="language-plaintext highlighter-rouge">settings.py</code> file:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">ROTATING_PROXY_LIST</span> <span class="o">=</span> <span class="p">[</span>
  <span class="sh">'</span><span class="s">host1:port1</span><span class="sh">'</span><span class="p">,</span>
  <span class="sh">'</span><span class="s">host2:port2</span><span class="sh">'</span><span class="p">,</span>
<span class="p">]</span>
</pre></table></code></div></div><p>Or use <code class="language-plaintext highlighter-rouge">ROTATING_PROXY_LIST_PATH</code> to configure to the proxies file:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">ROTATING_PROXY_LIST_PATH</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/my/path/proxies.txt</span><span class="sh">'</span>
</pre></table></code></div></div><p>View detailed docs of this library at <a href="https://github.com/TeamHG-Memex/scrapy-rotating-proxies">https://github.com/TeamHG-Memex/scrapy-rotating-proxies</a>.</p><p>Since the website doesn’t have a comment section under articles, everyone can discuss and give feedback to me at this GITHUB DISCUSSION: <a href="https://github.com/orgs/demanejar/discussions/1">https://github.com/orgs/demanejar/discussions/1</a>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/en/categories/crawler/'>Crawler</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/en/tags/crawler/" class="post-tag no-text-decoration" >Crawler</a> <a href="/en/tags/scrapy/" class="post-tag no-text-decoration" >Scrapy</a> <a href="/en/tags/alonhadat/" class="post-tag no-text-decoration" >alonhadat</a> <a href="/en/tags/proxy/" class="post-tag no-text-decoration" >proxy</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Configuring Proxy for Scrapy Project - De Manejar&url=https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Configuring Proxy for Scrapy Project - De Manejar&u=https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Configuring Proxy for Scrapy Project - De Manejar&url=https://demanejar.github.io/en/posts/add-proxy-to-scrapy-project/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/en/posts/redis-101-(part-1)/">Redis 101 (Part I)</a><li><a href="/en/posts/Kafka-In-Depth/">Kafka In Depth</a><li><a href="/en/posts/Apache-Nifi/">Understanding Apache Nifi</a><li><a href="/en/posts/Docker/">Docker Basics and Practice</a><li><a href="/en/posts/hadoop-question/">Summary of questions about Apache Hadoop</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/en/tags/bigdata/">Bigdata</a> <a class="post-tag" href="/en/tags/crawler/">Crawler</a> <a class="post-tag" href="/en/tags/scrapy/">Scrapy</a> <a class="post-tag" href="/en/tags/apache-hadoop/">Apache Hadoop</a> <a class="post-tag" href="/en/tags/hadoop/">Hadoop</a> <a class="post-tag" href="/en/tags/hdfs/">HDFS</a> <a class="post-tag" href="/en/tags/alonhadat/">alonhadat</a> <a class="post-tag" href="/en/tags/hadoop-yarn/">Hadoop Yarn</a> <a class="post-tag" href="/en/tags/selenium/">Selenium</a> <a class="post-tag" href="/en/tags/data-ingestion/">Data Ingestion</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/en/posts/crawl-1000-website-new-with-scrapy/"><div class="card-body"> <span class="timeago small" > Mar 1, 2023 <i class="unloaded">2023-03-01T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Crawl 1000 News Websites with Scrapy and MySQL</h3><div class="text-muted small"><p> If we write 1 spider to analyze information for each website, it will be very time-consuming, especially for news websites. There are thousands of different news websites and they’re still growing ...</p></div></div></a></div><div class="card"> <a href="/en/posts/crawl-housing-data-from-alonhadat/"><div class="card-body"> <span class="timeago small" > Jan 24, 2023 <i class="unloaded">2023-01-24T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Crawl Housing Data from Alonhadat with Scrapy</h3><div class="text-muted small"><p> In this article, I will introduce in detail how to create a project with Scrapy and use it to analyze and extract housing data from the Alonhadat website. If your machine doesn’t have Scrapy yet, y...</p></div></div></a></div><div class="card"> <a href="/en/posts/scrapy-shell/"><div class="card-body"> <span class="timeago small" > Apr 1, 2023 <i class="unloaded">2023-04-01T20:52:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Introduction to Scrapy Shell</h3><div class="text-muted small"><p> Every time we write a spider, we have to write many css selector and xpath segments to analyze information, and many times we don’t know if they’re correct or not. Each time like that, we have to r...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/en/posts/crawl-housing-data-from-alonhadat/" class="btn btn-outline-primary" prompt="Older"><p>Crawl Housing Data from Alonhadat with Scrapy</p></a> <a href="/en/posts/crawl-1000-website-new-with-scrapy/" class="btn btn-outline-primary" prompt="Newer"><p>Crawl 1000 News Websites with Scrapy and MySQL</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2026 <a href="https://twitter.com/DeManejar">demanejar</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div></div><script type="text/javascript"> var links = document.links; for (var i = 0, linksLength = links.length; i < linksLength; i++) { if (links[i].hostname != window.location.hostname) { links[i].target = '_blank'; } } </script></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/en/tags/bigdata/">Bigdata</a> <a class="post-tag" href="/en/tags/crawler/">Crawler</a> <a class="post-tag" href="/en/tags/scrapy/">Scrapy</a> <a class="post-tag" href="/en/tags/apache-hadoop/">Apache Hadoop</a> <a class="post-tag" href="/en/tags/hadoop/">Hadoop</a> <a class="post-tag" href="/en/tags/hdfs/">HDFS</a> <a class="post-tag" href="/en/tags/alonhadat/">alonhadat</a> <a class="post-tag" href="/en/tags/hadoop-yarn/">Hadoop Yarn</a> <a class="post-tag" href="/en/tags/selenium/">Selenium</a> <a class="post-tag" href="/en/tags/data-ingestion/">Data Ingestion</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/en/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://demanejar.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
